{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fatal-broadway",
   "metadata": {},
   "source": [
    "Uniform=1\n",
    "All_features=2\n",
    "Titlebody_features=3\n",
    "URL_features=4\n",
    "Anti_optimal=5\n",
    "(logging, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-garbage",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eight-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (1,2) uniform logging, tree_all for target (optimal)\n",
    "# (1,3) uniform logging, tree_titlebody for target (suboptimal)\n",
    "# (1,4) uniform logging, tree_url for target (suboptimal)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in All body url\n",
    "\t\tdo\n",
    "            for approach in Mean OnPolicy IPS IPS_SN PI PI_SN \n",
    "            do\n",
    "                python Parallel.py -t 0 -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.LogUniform.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "governing-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (1,5) uniform logging, tree_all anti for target (anti suboptimal)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "ef=All\n",
    "anti=True\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in Mean OnPolicy IPS IPS_SN PI PI_SN \n",
    "\t\tdo\n",
    "\t\t\tpython Parallel.py -t 0 -ea ${anti} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.anti.LogUniform.${approach} &\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "innovative-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (2,2) tree_all (t=1) logging, tree_all for target (optimal)\n",
    "# (2,3) tree_all logging, tree_titlebody for target (suboptimal)\n",
    "# (2,4) tree_all logging, tree_url for target (suboptimal)\n",
    "# (3,2)(3,3)(3,4)\n",
    "# (4,2)(4,3)(4,4)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in All body url\n",
    "\t\tdo\n",
    "            for lf in All body url\n",
    "            do\n",
    "                for approach in Mean OnPolicy IPS IPS_SN PI PI_SN \n",
    "                do\n",
    "                    python Parallel.py -t 1 -lf ${lf} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.Log.${lf}.${approach} &\n",
    "                done\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-indication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "orange-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (2,5) tree_all logging, tree_all anti for target (anti suboptimal)\n",
    "#(3,5)(4,5)\n",
    "M=100\n",
    "L=10\n",
    "ef=All\n",
    "anti=True\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in Mean OnPolicy IPS IPS_SN PI PI_SN \n",
    "\t\tdo\n",
    "            for lf in All body url\n",
    "            do\n",
    "                python Parallel.py -t 1 -lf ${lf} -ea ${anti} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.anti.Log.${lf}.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sustained-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (5,2)(5,3)(5,4)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in All body url\n",
    "\t\tdo\n",
    "            for lf in All\n",
    "            do\n",
    "                for approach in Mean OnPolicy IPS IPS_SN PI PI_SN \n",
    "                do\n",
    "                    python Parallel.py -t 1 -lf ${lf} -la True -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.Log.${lf}.anti.${approach} &\n",
    "                done\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "comparative-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (5,5) tree_all logging anti, tree_all anti for target (anti suboptimal)\n",
    "M=100\n",
    "L=10\n",
    "ef=All\n",
    "anti=True\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in Mean OnPolicy IPS IPS_SN PI PI_SN \n",
    "\t\tdo\n",
    "            for lf in All\n",
    "            do\n",
    "                python Parallel.py -t 1 -lf ${lf} -la ${anti} -ea ${anti} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.anti.Log.${lf}.anti.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-raise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floppy-allowance",
   "metadata": {},
   "source": [
    "# DM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-envelope",
   "metadata": {},
   "source": [
    "For my DM I need to use some other environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "micro-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# only for test!!!!\n",
    "# (1,2) uniform logging, tree_all for target (optimal)\n",
    "# (1,3) uniform logging, tree_titlebody for target (suboptimal)\n",
    "# (1,4) uniform logging, tree_url for target (suboptimal)\n",
    "\n",
    "M=3\n",
    "L=2\n",
    "\n",
    "for metric in ERR\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in url\n",
    "\t\tdo\n",
    "            for approach in DM_tree    DM_ridge  \n",
    "            do\n",
    "                python Parallel.py -t 0 -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.LogUniform.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "proper-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (1,2) uniform logging, tree_all for target (optimal)\n",
    "# (1,3) uniform logging, tree_titlebody for target (suboptimal)\n",
    "# (1,4) uniform logging, tree_url for target (suboptimal)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in All body url\n",
    "\t\tdo\n",
    "            for approach in DM_tree  DM_lasso  DMc_lasso  DM_ridge  DMc_ridge DM_50\n",
    "            do\n",
    "                python Parallel.py -t 0 -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.LogUniform.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "green-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (1,5) uniform logging, tree_all anti for target (anti suboptimal)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "ef=All\n",
    "anti=True\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in DM_tree  DM_lasso  DMc_lasso  DM_ridge  DMc_ridge DM_50\n",
    "\t\tdo\n",
    "\t\t\tpython Parallel.py -t 0 -ea ${anti} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.anti.LogUniform.${approach} &\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "juvenile-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (2,2) tree_all (t=1) logging, tree_all for target (optimal)\n",
    "# (2,3) tree_all logging, tree_titlebody for target (suboptimal)\n",
    "# (2,4) tree_all logging, tree_url for target (suboptimal)\n",
    "# (3,2)(3,3)(3,4)\n",
    "# (4,2)(4,3)(4,4)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in All body url\n",
    "\t\tdo\n",
    "            for lf in All body url\n",
    "            do\n",
    "                for approach in DM_tree  DM_lasso  DMc_lasso  DM_ridge  DMc_ridge DM_50\n",
    "                do\n",
    "                    python Parallel.py -t 1 -lf ${lf} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.Log.${lf}.${approach} &\n",
    "                done\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coastal-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#(2,5) tree_all logging, tree_all anti for target (anti optimal)\n",
    "#(3,5)(4,5)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "ef=All\n",
    "anti=True\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in DM_tree  DM_lasso  DMc_lasso  DM_ridge  DMc_ridge DM_50\n",
    "\t\tdo\n",
    "            for lf in All body url\n",
    "            do\n",
    "                python Parallel.py -t 1 -lf ${lf} -ea ${anti} -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.anti.Log.${lf}.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "worth-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (5,2)(5,3)(5,4)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor ef in All body url\n",
    "\t\tdo\n",
    "            for lf in All\n",
    "            do\n",
    "                for approach in DM_tree  DM_lasso  DMc_lasso  DM_ridge  DMc_ridge DM_50\n",
    "                do\n",
    "                    python Parallel.py -t 1 -lf ${lf} -la True -ef ${ef} -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.${ef}.Log.${lf}.anti.${approach} &\n",
    "                done\n",
    "            done\n",
    "\t\tdone\n",
    "        \n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "subject-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# (5,5) tree_all logging anti, tree_all anti for target (anti optimal)\n",
    "\n",
    "M=100\n",
    "L=10\n",
    "ef=All\n",
    "anti=True\n",
    "\n",
    "for metric in ERR NDCG\n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in DM_tree  DM_lasso  DMc_lasso  DM_ridge  DMc_ridge DM_50\n",
    "\t\tdo\n",
    "            for lf in All \n",
    "            do\n",
    "                python Parallel.py -t 1 -lf ${lf} -la True -ea ${anti} -ef ef -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 25 &> eval.log.${metric}.${M}.${L}.${eval}.anti.Log.${lf}.anti.${approach} &\n",
    "            done\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-transparency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-suicide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-bishop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-democrat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-dealer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mysterious-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# uniform logging, tree_all for target (optimal)\n",
    "\n",
    "M=10\n",
    "L=5\n",
    "\n",
    "for metric in ERR \n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in DM_ridge Mean OnPolicy\n",
    "\t\tdo\n",
    "\t\t\tpython Parallel.py -t 0 -ef \"all\" -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 2 &> eval.log.${metric}.${M}.${L}.${eval}.LogUniform.notanti.${approach} &\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stainless-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# uniform logging, tree_all for target (optimal)\n",
    "\n",
    "M=10\n",
    "L=5\n",
    "\n",
    "for metric in ERR \n",
    "do\n",
    "\tfor eval in tree\n",
    "\tdo\n",
    "\t\tfor approach in DM_ridge\n",
    "\t\tdo\n",
    "\t\t\tpython Parallel.py -t 0 -ef \"all\" -m ${M} -l ${L} -v ${metric} -e ${eval} -a ${approach} --start 0 --stop 2 &> eval.log.${metric}.${M}.${L}.${eval}.LogUniform.notanti.${approach} &\n",
    "\t\tdone\n",
    "\tdone\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-apparel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sought-illustration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "monthly-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy, scipy.sparse\n",
    "lil = scipy.sparse.lil_matrix((100, 100), dtype=int)\n",
    "scipy.sparse.triu(lil)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "congressional-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "through-livestock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decent-reform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "boxed-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-majority",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
